{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Selection\n",
    "Our main topic is Brexit. We need to use all the quotations from 2016 to 2020 and then extract the quotations containing the keyword \"Brexit\". \n",
    "\n",
    "Since the dataset is extremely large, we use chunksize to handle it. Then save all the data into json files. Finally we combine all these json files into csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk, year, idx):\n",
    "    chunk['date'] = chunk.date.apply(lambda x: x.date())  \n",
    "    Brexit = chunk[(chunk[\"quotation\"].str.contains(\"Brexit\"))] \n",
    "    transformed = Brexit[[\"date\",\"quotation\",\"speaker\",\"qids\",\"probas\"]]\n",
    "    transformed.to_json('{}_chunk_{}.json'.format(year,idx))\n",
    "\n",
    "for i in range(2016,2021):\n",
    "    filename = 'quotes-{}.json.bz2'.format(i) \n",
    "    with pd.read_json(filename, lines=True, compression='bz2', chunksize=1000000) as df_reader:\n",
    "        for idx, chunk in enumerate(df_reader):\n",
    "            process_chunk(chunk, i, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_2016 = []\n",
    "for i in range(14):\n",
    "    json = pd.read_json(\"2016_chunk_{}.json\".format(i))\n",
    "    json_list_2016.append(json)\n",
    "brexit_2016 = pd.concat(json_list_2016)\n",
    "brexit_2016.to_csv(\"brexit_2016.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_2017 = []\n",
    "for i in range(27):\n",
    "    json = pd.read_json(\"2017_chunk_{}.json\".format(i))\n",
    "    json_list_2017.append(json)\n",
    "brexit_2017 = pd.concat(json_list_2017)\n",
    "brexit_2017.to_csv(\"brexit_2017.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_2018 = []\n",
    "for i in range(28):\n",
    "    json = pd.read_json(\"2018_chunk_{}.json\".format(i))\n",
    "    json_list_2018.append(json)\n",
    "brexit_2018 = pd.concat(json_list_2018)\n",
    "brexit_2018.to_csv(\"brexit_2018.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_2019 = []\n",
    "for i in range(22):\n",
    "    json = pd.read_json(\"2019_chunk_{}.json\".format(i))\n",
    "    json_list_2019.append(json)\n",
    "brexit_2019 = pd.concat(json_list_2019)\n",
    "brexit_2019.to_csv(\"brexit_2019.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_2020 = []\n",
    "for i in range(6):\n",
    "    json = pd.read_json(\"2020_chunk_{}.json\".format(i))\n",
    "    json_list_2020.append(json)\n",
    "brexit_2020 = pd.concat(json_list_2020)\n",
    "brexit_2020.to_csv(\"brexit_2020.csv\", index = False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
